

Training a Neural Network to Understand Spoken Commands
Group Members
Nicholas Hefner 014501147
Arthur Ho 025847586
Hsuan-Yu Lin 035276148
Link to Dataset:
https://www.tensorflow.org/datasets/catalog/speech_commands
The datasets consists of over 105,000 audio files in wav format of people saying 35
different words
Project Description:
The purpose of this dataset provided by Google’s Brain Team is to allow developers to
use speech to control their application. In this dataset, there are 65,000 audio files of 30
different spoken commands, such as “Yes”, “No”, “Stop”, and even spoken names. This dataset
includes background noise to allow for data augmentation for more robust training data.
The goal of this project is to train and test different convolutional neural networks with
varying depth and regularization strategies to compare their accuracy on the Speech
Commands dataset. This comparison will help determine how model complexity interacts with
dataset variability in influencing recognition performance.
